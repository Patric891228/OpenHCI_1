Introduction

This project explores the potential of using AI techniques, specifically Large Language Models (LLM) and Virtual Language Models (VLM), in conjunction with an XR headset to enhance public speaking and interview preparation. Our system aims to reduce anxiety and improve performance by creating a realistic, immersive training environment.

Motivation

Studies have shown that 77% of people experience anxiety related to public speaking (Fraculj & Kovacic, 2022), and 93% have interview-related anxiety (JDP, 2022). Traditional methods of practice, such as speaking to a mirror or recording oneself, often fall short in mimicking the stress and unpredictability of real-life scenarios.

Features

High-Fidelity Virtual Environments: The system offers highly realistic virtual settings to simulate public speaking and interviews.

Mixed Reality Audience: Combines AI-generated avatars and real human participants to create a pressure-inducing audience, blurring the lines between virtual and real.

Real-Time Interaction and Feedback: Utilizes LLMs to generate real-time questions and feedback, enhancing the realism and adaptability of the training.

Performance Analytics: Provides detailed performance reports and suggestions for improvement based on user interactions.

System Design

Immersive VR Experience: Users wear a VR headset to enter a virtual environment where they can practice speaking in front of a mixed audience.

AI and Human Integration: Real humans participate alongside AI avatars, providing dynamic and unpredictable interactions.
Real-Time Q&A: The system uses LLMs to generate questions based on past exam questions and user input, ensuring relevant and challenging interactions.

Data-Driven Feedback: After each session, users receive comprehensive feedback on their performance, including strengths and areas for improvement.

User Journey

The user journey is carefully crafted to replicate the stages of real-life public speaking and interviews:

Preparation: Users set their scenario and goals.

Simulation: Users practice their presentation or interview in the virtual environment.

Real-Time Interaction: The system generates questions and feedback during the session.

Post-Session Analysis: Users receive a detailed report on their performance.

Technical Details

Large Language Models (LLM): Utilized for generating realistic and contextually appropriate questions and feedback.

Speech-To-Text & Text-To-Speech: Enables real-time interaction and feedback in the virtual environment.

Prompt Engineering: Ensures the system generates relevant and challenging prompts for users.

Immersive Virtual Reality Experience: Provides a realistic and engaging environment for users to practice.

Future Work

Enhanced AI Capabilities: Improve the LLM's ability to evaluate and give feedback on speech techniques.

Expanded Scenarios: Include a wider range of scenarios for different public speaking and interview contexts.

User Customization: Allow users to customize their training environment and feedback preferences.














